{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from bert-tensorflow) (1.11.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!apt install wget\n",
    "!pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "from bert import modeling\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/counts_1grams.txt') as fopen:\n",
    "    f = fopen.read().split('\\n')[:-1]\n",
    "    \n",
    "words = {}\n",
    "for l in f:\n",
    "    w, c = l.split('\\t')\n",
    "    c = int(c)\n",
    "    words[w] = c + words.get(w, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original from https://github.com/cbaziotis/ekphrasis/blob/master/ekphrasis/classes/spellcorrect.py\n",
    "# improved it\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "class SpellCorrector:\n",
    "    \"\"\"\n",
    "    The SpellCorrector extends the functionality of the Peter Norvig's\n",
    "    spell-corrector in http://norvig.com/spell-correct.html\n",
    "    \"\"\"\n",
    "    REGEX_TOKEN = re.compile(r'\\b[a-z]{2,}\\b')\n",
    "\n",
    "    def __init__(self, words):\n",
    "        \"\"\"\n",
    "        :param corpus: the statistics from which corpus to use for the spell correction.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.WORDS = words\n",
    "        self.N = sum(self.WORDS.values())\n",
    "              \n",
    "    @staticmethod\n",
    "    def tokens(text):\n",
    "        return REGEX_TOKEN.findall(text.lower())\n",
    "\n",
    "    def P(self, word):\n",
    "        \"\"\"\n",
    "        Probability of `word`.\n",
    "        \"\"\"\n",
    "        return self.WORDS[word] / self.N\n",
    "\n",
    "    def most_probable(self, words):\n",
    "        _known = self.known(words)\n",
    "        if _known:\n",
    "            return max(_known, key=self.P)\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    @staticmethod\n",
    "    def edit_step(word):\n",
    "        \"\"\"\n",
    "        All edits that are one edit away from `word`.\n",
    "        \"\"\"\n",
    "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "        deletes = [L + R[1:] for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "        inserts = [L + c + R for L, R in splits for c in letters]\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "    def edits2(self, word):\n",
    "        \"\"\"\n",
    "        All edits that are two edits away from `word`.\n",
    "        \"\"\"\n",
    "        return (e2 for e1 in self.edit_step(word)\n",
    "                for e2 in self.edit_step(e1))\n",
    "\n",
    "    def known(self, words):\n",
    "        \"\"\"\n",
    "        The subset of `words` that appear in the dictionary of WORDS.\n",
    "        \"\"\"\n",
    "        return set(w for w in words if w in self.WORDS)\n",
    "\n",
    "    def edit_candidates(self, word, assume_wrong=False, fast=True):\n",
    "        \"\"\"\n",
    "        Generate possible spelling corrections for word.\n",
    "        \"\"\"\n",
    "\n",
    "        if fast:\n",
    "            ttt = self.known(self.edit_step(word)) or {word}\n",
    "        else:\n",
    "            ttt = self.known(self.edit_step(word)) or self.known(self.edits2(word)) or {word}\n",
    "        \n",
    "        ttt = self.known([word]) | ttt\n",
    "        return list(ttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrector = SpellCorrector(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rife', 'give', 'life', 'gibe', 'wife', 'gift']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#possible_states = corrector.edit_candidates('eting')\n",
    "possible_states = corrector.edit_candidates('gife')\n",
    "possible_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_VOCAB = 'uncased_L-12_H-768_A-12/vocab.txt'\n",
    "BERT_INIT_CHKPNT = 'uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "BERT_CONFIG = 'uncased_L-12_H-768_A-12/bert_config.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization.validate_case_matches_checkpoint(True,BERT_INIT_CHKPNT)\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "      vocab_file=BERT_VOCAB, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**mask** me something to eat'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text = 'scientist suggests eting burger can lead to obesity'\n",
    "text = 'gife me something to eat'\n",
    "#text_mask = text.replace('eting', '**mask**')\n",
    "text_mask = text.replace('gife', '**mask**')\n",
    "text_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_masked_ids(tokens, mask_ind):\n",
    "    masked_tokens = tokens[:]\n",
    "    masked_tokens[mask_ind] = \"[MASK]\"\n",
    "    masked_tokens = [\"[CLS]\"] + masked_tokens + [\"[SEP]\"]\n",
    "    masked_ids = tokenizer.convert_tokens_to_ids(masked_tokens)\n",
    "    return masked_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = modeling.BertConfig.from_json_file(BERT_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bert.modeling.BertConfig at 0x7f611c4d8c18>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,):\n",
    "        self.X = tf.placeholder(tf.int32, [None, None])\n",
    "        \n",
    "        model = modeling.BertModel(\n",
    "            config=bert_config,\n",
    "            is_training=False,\n",
    "            input_ids=self.X,\n",
    "            use_one_hot_embeddings=False)\n",
    "        \n",
    "        self.output_layer = model.get_sequence_output()\n",
    "        self.embedding = model.get_embedding_table()\n",
    "        \n",
    "#         print(modeling.get_activation(bert_config.hidden_act))\n",
    "#         print(self.output_layer.shape)\n",
    "#         print(self.embedding.shape)\n",
    "#         print(bert_config.hidden_size)\n",
    "#         print(bert_config.initializer_range)\n",
    "        with tf.variable_scope('cls/predictions'):\n",
    "            with tf.variable_scope('transform'):\n",
    "                input_tensor = tf.layers.dense(\n",
    "                    self.output_layer,\n",
    "                    units = bert_config.hidden_size,\n",
    "                    activation = modeling.get_activation(bert_config.hidden_act),\n",
    "                    kernel_initializer = modeling.create_initializer(\n",
    "                        bert_config.initializer_range\n",
    "                    ),\n",
    "                )\n",
    "                input_tensor = modeling.layer_norm(input_tensor)\n",
    "                print(input_tensor.shape)\n",
    "            \n",
    "            output_bias = tf.get_variable(\n",
    "            'output_bias',\n",
    "            shape = [bert_config.vocab_size],\n",
    "            initializer = tf.zeros_initializer(),\n",
    "            )\n",
    "            logits = tf.matmul(input_tensor, self.embedding, transpose_b = True)\n",
    "            self.logits = tf.nn.bias_add(logits, output_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 768)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "var_lists = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'cls/predictions/output_bias:0' shape=(30522,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'cls')\n",
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(var_list = var_lists + cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(var_list = var_lists + cls)\n",
    "#saver = tf.train.Saver(var_list = var_lists)\n",
    "saver.restore(sess, BERT_INIT_CHKPNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rife me something to eat',\n",
       " 'give me something to eat',\n",
       " 'life me something to eat',\n",
       " 'gibe me something to eat',\n",
       " 'wife me something to eat',\n",
       " 'gift me something to eat']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replaced_masks = [text_mask.replace('**mask**', state) for state in possible_states]\n",
    "replaced_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'give me something to eat'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = replaced_masks[1]\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['give', 'me', 'something', 'to', 'eat']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sent)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[101, 103, 2033, 2242, 2000, 4521, 102],\n",
       " [101, 2507, 103, 2242, 2000, 4521, 102],\n",
       " [101, 2507, 2033, 103, 2000, 4521, 102],\n",
       " [101, 2507, 2033, 2242, 103, 4521, 102],\n",
       " [101, 2507, 2033, 2242, 2000, 103, 102]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = [tokens_to_masked_ids(tokens, i) for i in range(len(tokens))]\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = sess.run([model.embedding, \n",
    "                  model.output_layer,\n",
    "                  tf.nn.softmax(model.logits)], feed_dict = {model.X: input_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30522, 768)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = preds[0]\n",
    "output_layer = preds[1]\n",
    "embedding.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 7, 768)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
